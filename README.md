#  ClasificaciÃ³n de Ingredientes de Cocina con Vision Transformers

Proyecto final para la materia **VisiÃ³n por Computadora III** - CEIA

##  DescripciÃ³n

Sistema de clasificaciÃ³n automÃ¡tica de ingredientes de cocina utilizando Vision Transformers (ViT), comparando diferentes arquitecturas como DeiT y MobileViT. El sistema puede identificar 40 tipos diferentes de ingredientes comunes, con aplicaciones en asistentes de cocina inteligentes, gestiÃ³n de inventario y recomendaciÃ³n de recetas.

##  Objetivos

- Implementar y comparar diferentes arquitecturas de Vision Transformers (DeiT-tiny, MobileViT)
- Realizar experimentaciÃ³n sistemÃ¡tica con hiperparÃ¡metros y tÃ©cnicas de optimizaciÃ³n
- Evaluar el rendimiento con mÃ©tricas apropiadas para clasificaciÃ³n multi-clase
- Desarrollar un pipeline de entrenamiento reproducible con tracking MLflow
- Analizar el comportamiento del modelo en clases visualmente similares

##  Dataset

**Food-Ingredient-Dataset-51** (Kaggle)
- **51 clases** de frutas y vegetales
- **~5,000+ imÃ¡genes** totales
- **Clases incluidas**:
  - Frutas: apple, banana, grapes, kiwi, lemon, mango, orange, pear, pineapple, pomegranate, watermelon, grapefruit, lime, peach, plum, strawberry
  - Vegetales: beetroot, bell_pepper, cabbage, capsicum, carrot, cauliflower, chilli_pepper, corn, cucumber, eggplant, garlic, ginger, lettuce, onion, paprika, peas, potato, radish, soy_beans, spinach, sweetcorn, sweetpotato, tomato, turnip, broccoli, green_beans, mushroom, okra, pumpkin, zucchini, asparagus, avocado, celery, jalepeno, red_chilli
- **Fuente**: [Kaggle - Food-Ingredient-Dataset-51](https://www.kaggle.com/datasets/sunnyagarwal427444/food-ingredient-dataset-51)
- **Alternativa**: [HuggingFace Mirror](https://huggingface.co/datasets/SunnyAgarwal4274/Food_Ingredients)

##  Estructura del Proyecto

```
CEIA-VPC3/
â”œâ”€â”€ config/              # Configuraciones del proyecto
â”‚   â”œâ”€â”€ config.yaml     # ConfiguraciÃ³n principal
â”‚   â””â”€â”€ mlflow_config.py
â”œâ”€â”€ data/                # Datasets (raw, processed, splits)
â”‚   â”œâ”€â”€ raw/            # Dataset original de Roboflow
â”‚   â”œâ”€â”€ processed/      # ImÃ¡genes preprocesadas
â”‚   â””â”€â”€ splits/         # Train/val/test splits
â”œâ”€â”€ notebooks/           # Jupyter notebooks para EDA
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_data_exploration.ipynb
â”‚   â””â”€â”€ 03_results_analysis.ipynb
â”œâ”€â”€ src/                 # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ data/           # Dataset, transforms, dataloaders
â”‚   â”œâ”€â”€ models/         # Arquitecturas de modelos (DeiT, MobileViT)
â”‚   â”œâ”€â”€ training/       # LÃ³gica de entrenamiento
â”‚   â”œâ”€â”€ evaluation/     # MÃ©tricas y visualizaciones
â”‚   â””â”€â”€ utils/          # Utilidades generales
â”œâ”€â”€ experiments/         # Scripts de experimentaciÃ³n
â”‚   â”œâ”€â”€ baseline.py
â”‚   â”œâ”€â”€ experiment_runner.py
â”‚   â””â”€â”€ configs/        # Configuraciones de experimentos
â”œâ”€â”€ scripts/            # Scripts de ejecuciÃ³n
â”‚   â”œâ”€â”€ download_data.py
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ outputs/            # Modelos, figuras, resultados
â”‚   â”œâ”€â”€ models/         # Checkpoints de modelos
â”‚   â”œâ”€â”€ figures/        # GrÃ¡ficos y visualizaciones
â”‚   â””â”€â”€ results/        # MÃ©tricas y reportes
â”œâ”€â”€ mlruns/             # MLflow tracking
â”œâ”€â”€ assets/             # Recursos adicionales
â”‚   â”œâ”€â”€ images/         # ImÃ¡genes para README
â”‚   â”œâ”€â”€ diagrams/       # Diagramas de arquitectura
â”‚   â””â”€â”€ presentation/   # Slides de presentaciÃ³n
â””â”€â”€ docs/               # DocumentaciÃ³n e informe tÃ©cnico
```

##  Setup

### Requisitos Previos

- Python 3.10+
- CUDA 11.8+ (para entrenamiento en GPU)
- [uv](https://github.com/astral-sh/uv) - Gestor de paquetes ultrarrÃ¡pido

### InstalaciÃ³n de uv

```bash
# Linux/macOS
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### Setup del Proyecto

```bash
# Clonar/navegar al proyecto
cd /home/martin/Documents/CEIA/CEIA-VPC3

# Crear entorno virtual con uv
uv venv

# Activar entorno virtual
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows

# Instalar dependencias
uv pip install -r requirements.txt

# Instalar el proyecto en modo desarrollo
uv pip install -e .
```

### Descargar Dataset

```bash
# OpciÃ³n 1: Usar script de descarga automÃ¡tica (Kaggle API)
python scripts/download_kaggle.py

# OpciÃ³n 2: Manual desde Kaggle
# 1. Ir a: https://www.kaggle.com/datasets/sunnyagarwal427444/food-ingredient-dataset-51
# 2. Click "Download" (requiere cuenta de Kaggle)
# 3. Extraer ZIP en data/raw/

# OpciÃ³n 3: Desde HuggingFace
# https://huggingface.co/datasets/SunnyAgarwal4274/Food_Ingredients
```

**Setup de Kaggle API:**
```bash
# 1. Obtener credentials:
#    - Ir a https://www.kaggle.com/settings/account
#    - Scroll a 'API' â†’ 'Create New Token'
#    - Descargar kaggle.json

# 2. Agregar al .env:
#    KAGGLE_USERNAME=your_username
#    KAGGLE_KEY=your_key_from_kaggle_json

# 3. Ejecutar descarga:
python scripts/download_kaggle.py
```

### Configurar Databricks MLflow

```bash
# 1. Crear archivo .env en la raÃ­z del proyecto
cp .env.example .env

# 2. Editar .env con tus credenciales de Databricks
# DATABRICKS_HOST=https://tu-workspace.cloud.databricks.com
# DATABRICKS_TOKEN=tu_personal_access_token

# 3. Obtener tu PAT (Personal Access Token):
#    - Ir a Databricks workspace
#    - User Settings â†’ Developer â†’ Access Tokens
#    - Generate New Token
#    - Copiar token al .env

# 4. Probar conexiÃ³n
python config/mlflow_config.py
```

**Nota**: El archivo `.env` estÃ¡ en `.gitignore` y NUNCA debe subirse a git.

## ðŸ”¬ ExperimentaciÃ³n

### Experimentos Planificados

1. **Baseline Models**
   - DeiT-tiny con capas congeladas
   - MobileViT-small baseline

2. **Arquitecturas**
   - ComparaciÃ³n DeiT-tiny vs MobileViT-small vs MobileViT-xx-small
   - Fine-tuning completo vs parcial

3. **OptimizaciÃ³n**
   - Learning rates: [1e-5, 5e-5, 1e-4, 5e-4]
   - Optimizers: Adam, AdamW, SGD
   - Schedulers: Cosine, Step Decay, ReduceLROnPlateau

4. **Data Augmentation**
   - Baseline: Resize + Normalize
   - Medium: + HorizontalFlip + Rotation + ColorJitter
   - Heavy: + RandomResizedCrop + Mixup

5. **RegularizaciÃ³n**
   - Dropout: [0.1, 0.3, 0.5]
   - Weight decay: [1e-5, 1e-4, 1e-3]
   - Label smoothing: [0, 0.1]

### Ejecutar Experimentos

```bash
# Baseline
python experiments/baseline.py

# Experimento especÃ­fico
python scripts/train.py --config experiments/configs/exp_augmentation.yaml

# Runner de mÃºltiples experimentos
python experiments/experiment_runner.py
```

### Monitoreo con MLflow

```bash
# OpciÃ³n 1: Ver en Databricks UI
# - Ir a tu workspace de Databricks
# - Machine Learning â†’ Experiments
# - Buscar "ingredients_classification"

# OpciÃ³n 2: MLflow UI local (alternativo)
mlflow ui --backend-store-uri databricks --port 5000
# Abrir en navegador: http://localhost:5000
```

##  MÃ©tricas de EvaluaciÃ³n

- **Accuracy** (overall y por clase)
- **Balanced Accuracy** (para manejar desbalance)
- **Precision, Recall, F1-score** (macro y weighted)
- **Top-3 y Top-5 Accuracy**
- **Confusion Matrix** con anÃ¡lisis de clases confundidas
- **Learning Curves** (train/val loss y accuracy)
- **Inference Time** y eficiencia computacional

##  Aplicaciones Potenciales

-  **App mÃ³vil**: Reconocimiento de ingredientes en tiempo real
-  **GestiÃ³n de inventario**: Control automÃ¡tico de stock en cocinas
-  **RecomendaciÃ³n de recetas**: Sugerir recetas basadas en ingredientes disponibles
-  **Asistente de compras**: Lista inteligente de compras
-  **NutriciÃ³n**: AnÃ¡lisis nutricional automÃ¡tico de comidas

##  Resultados Preliminares

[Por completar despuÃ©s de experimentaciÃ³n]

##  Equipo

- MartÃ­n Brocca
- Ariadna Garmendia
- Carina Roldan

##  TecnologÃ­as Utilizadas

- **Deep Learning**: PyTorch, Timm, Transformers
- **MLOps**: MLflow, TensorBoard
- **Data**: Albumentations, Torchvision
- **VisualizaciÃ³n**: Matplotlib, Seaborn, Plotly
- **GestiÃ³n de Paquetes**: uv

##  Referencias

- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
- [Training data-efficient image transformers](https://arxiv.org/abs/2012.12877) (DeiT)
- [MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178)

##  Licencia

Este proyecto es parte del programa de CEIA (EspecializaciÃ³n en Inteligencia Artificial) y estÃ¡ destinado Ãºnicamente para fines educativos y acadÃ©micos.

---

**Materia**: VisiÃ³n por Computadora III - Vision Transformers  
**InstituciÃ³n**: CEIA  
**AÃ±o**: 2025